% \documentclass[final,twocolumn,5p]{elsarticle}
% \documentclass{sig-alternative}
\documentclass[conference]{IEEEtran}
% \documentclass[smallextended]{svjour3}
% \documentclass[preprint,12pt,3p,number]{elsarticle}
\usepackage{cite}
\usepackage{multirow}
\usepackage{color}
\usepackage{graphics} 
\usepackage{rotating}
\usepackage{eqparbox}
\usepackage{graphics}
\usepackage{colortbl} 
 \usepackage{mathptmx} \usepackage[scaled=.90]{helvet} \usepackage{courier}
\usepackage{balance}
\usepackage{picture}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[export]{adjustbox}
\renewcommand{\footnotesize}{\scriptsize}
\definecolor{lightgray}{gray}{0.8}
\definecolor{darkgray}{gray}{0.6}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newcommand{\crule}[3][darkgray]{\textcolor{#1}{\rule{#2}{#3}}}

\newcommand{\quart}[3]{\begin{picture}(100,6)%1
{\color{black}\put(#3,3){\circle*{4}}\put(#1,3){\line(1,0){#2}}}\end{picture}}
\definecolor{Gray}{gray}{0.95}
\definecolor{LightGray}{gray}{0.975}
\newcommand{\wei}[1]{\textcolor{red}{Wei: #1}} 
\newcommand{\Menzies}[1]{\textcolor{red}{Dr.Menzies: #1}} 

%% timm tricks
\newcommand{\bi}{\begin{itemize}[leftmargin=0.4cm]}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\tion}[1]{\S\ref{sect:#1}}
\newcommand{\fig}[1]{Figure~\ref{fig:#1}}
\newcommand{\tab}[1]{Table~\ref{tab:#1}}
\newcommand{\eq}[1]{Equation~\ref{eq:#1}}

%% space saving measures

\usepackage[shortlabels]{enumitem}  
\usepackage{url}
\begin{document}
% \begin{frontmatter}
\title{ Tuning for Software Analytics: is it Really Necessary?}
\author{Wei Fu }
\maketitle
\thispagestyle{plain}
\pagestyle{plain}

\begin{abstract}
Data mining algorithms have been widely used in software engineering to perform software 
analytics, like defect
prediction, effort estimation and text mining. But one of the “black arts” of data mining is setting
the tunings that control the miner. Nevertheless, we rarely tuned those parameters since we
reasoned that a data miner’s default tunings have been well-explored by the developers of
those algorithms.

In this work, taking defect prediction as an example, we investigated how parameter tuning can
affect the results of software analytics. For each experiment with different data sets (from open
source JAVA systems), we ran differential evolution as an optimizer to explore the tuning space
(as a first step) then tested the tunings.

Contrary to our prior expectations, we found these tunings were remarkably simple: it only
required tens, not thousands, of attempts to obtain very good results. For example, when
learning software defect predictors, this method can quickly find tunings that alter detection
precision from 0\% to 60\%.

Since the (1) the improvements are so large, and (2)the tuning is so simple, we need to change
standard methods in software analytics. At least for defect prediction, it is no longer enough to
just run a data miner and present the result.

\end{abstract}

\vspace{1mm}
\noindent
{\bf Keywords:} defect prediction, CART, random forest,
differential evolution,
search-based software engineering.
%  \maketitle 
\pagenumbering{arabic} %XXX delete before submission

\input{1.0section_introduction}

\input{2.0section_literaturereview}

\input{3.0section_experiment}

\input{4.0section_results}

\input{5.0section_reliability}

\input{6.0section_conclusion}

\input{7.0section_futurework}

\section*{Acknowledgments}
The work has partially funded by a National Science Foundation CISE CCF award \#1506586.
 
\vspace*{0.5mm}
 
 
\bibliographystyle{ieeetr}
% \bibliographystyle{elsarticle-num}

\bibliography{tuningpredictor}  

\balance

\end{document}
 
% \subsection{Implications}

% time for an end to era of data mining in se? moving on to a new phase of learning-as-optimization

% 1) learning is actually an optimization tasks (e.g. see fig2 of  learners climbing the roc curve hill in http://goo.gl/x2EaAm)

% 2) our learners are all contorted to do some tasks X (e.g. minimize expected value of entropy), then we assess them on score Y (recall). which is nuts. maybe we should build the goal predicate into the learner (e.g http://menzies.us/pdf/10which.pdf) 

% 3) given 1 + 2, maybe the whole paradigm of optimizing param selection is wrong. maybe what we need is a library of bees buzzing around making random choices (e.g. about descritziation) which other bees use, plus their own random choices (e.g. max depth of tree learned from discretized data) which is used by other bees, plus their own random choices (e.g. business users reading the models).  the funky thing here is that it can take some time before some of the bees (the discretizers) get feedback from the community of people using their decision (the tree learners). 




